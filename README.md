# Prompt-Engg
This project was done in Nov 2023

REPORT
I conducted a comprehensive series of experiments using the GPT-3.5-turbo model to assess its language capabilities, logical reasoning, and mathematical proficiency. The following provides an in-depth account of each task performed and the nuanced observations made:
1. Funny Conversation Prompt:
Initial attempts to generate a funny conversation between two art critics discussing a unique art piece (black canvas with a dot of blue paint) did not yield the desired humorous output. Despite refining the prompt and explicitly instructing the model to make fun of the painting, the responses lacked genuine humor. However, it consistently exhibited refined language skills but in terms of funny, the responses just featured expressions like "(chuckle/laugh)" next to the speakers' names.
2. Conversation Summarization:
The model was tasked with summarizing the previous conversation. Using a lower temperature (0.65) for an easier summary, the response was adequately clear and concise. However, the summary missed crucial details about the painting, indicating a potential limitation in retaining the important information.
3. Imaginative Painting Reaction:
Presenting the summary to the model, I requested an imaginative response about how the painting would react to the critics' conversation. Surprisingly, the model delivered a thoughtful and serious response, showcasing its ability to generate creative and contextually relevant content. However, attempts to evoke humor in this context were less successful.
4. Logical Reasoning and Random Values:
To assess the model's logical reasoning, I introduced random variables (e.g., people with 11 hands) and concluded with an unrelated question about the color of human blood. Remarkably, the model excelled in providing a logical sound answer to the question, demonstrating an impressive ability to reason through diverse scenarios.
5. Mathematical Calculations:
The model faced challenges when tasked with basic mathematical calculations. Despite multiple prompt adjustments and explicit instructions, achieving an accurate mean calculation proved elusive. This suggests a notable limitation in the model's mathematical proficiency.
6. Logical Argument Prompt:
The model was instructed to present a logical argument either in favor or against the statement "Artificial intelligence will replace human jobs." The model decided to agree with the statement, providing a coherent set of points. However, when subsequently challenged with a mean calculation task, the model struggled, revealing inconsistencies in performance across different cognitive domains.
7. Scenario Description:
When presented with a scenario where a person is holding an umbrella indoors, the model delivered a logically sound explanation, showcasing its ability to provide sensible responses to everyday scenarios.
8. Riddle Challenge:
A riddle challenge was introduced to evaluate the model's interpretive and reasoning capabilities. The model provided a different answer from the expected solution found online, but the response demonstrated logical coherence and sensibility.
Key Takeaways:
Linguistic Power:
The GPT-3.5-turbo model consistently demonstrated strong linguistic capabilities, producing refined and verbose responses across diverse prompts.
Humor Generation:
Despite the model's linguistic prowess, attempts to elicit genuinely funny responses were challenging. The model struggled to generate humor even with refined and explicit instructions.
Logical Reasoning:
The model exhibited remarkable logical reasoning skills, delivering coherent and sensible responses to scenarios, arguments, and unrelated questions.
Mathematical Proficiency:
Basic mathematical tasks, in the code mean calculation, posed a significant challenge for the model. Despite multiple attempts and adjustments, accurate mathematical computations remained elusive.
Imagination and Creativity:
The model displayed imaginative responses in scenarios and hypothetical situations, showcasing its ability to generate creative content.

In conclusion, while GPT-3.5-turbo demonstrates strengths in linguistic and logical reasoning tasks, there are notable limitations in generating humor and accurately performing mathematical computations. Understanding these nuanced strengths and weaknesses is essential for informed and effective utilization of the model across various applications. 
